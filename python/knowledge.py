import logging
from flask import Blueprint, render_template, current_app,session # current_appã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import os
import csv
# ---ã€‡å¤‰æ›´ç‚¹---
from database import get_db
from models import arrange_suggest
# ---ã“ã“ã¾ã§---
logger = logging.getLogger(__name__)

# 1. Blueprintã‚’å®šç¾© (å¤‰æ›´ãªã—)
bp = Blueprint('knowledge_bp', __name__, url_prefix='/knowledge')
    

FILE_GROUP_MAP = {
    'è±†çŸ¥è­˜(æ–™ç†).csv': 'æ–™ç†',
    'è±†çŸ¥è­˜(æƒé™¤).csv': 'æƒé™¤',    
    'è±†çŸ¥è­˜(å¯é£Ÿéƒ¨).csv': 'å¯é£Ÿéƒ¨',  
    'è±†çŸ¥è­˜(ãã®ä»–).csv': 'ãã®ä»–'  
}

# ğŸ’¡ CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ç›¸å¯¾ãƒ‘ã‚¹ (staticãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹)
CSV_DIR_RELATIVE_PATH = os.path.join("static", "excel")  # å°æ–‡å­—ã®staticã«ä¿®æ­£

def load_knowledge_data():
    """æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§CSVèª­ã¿è¾¼ã¿ï¼ˆpandasä¸ä½¿ç”¨ï¼‰"""
    base_dir = os.path.dirname(current_app.root_path)
    csv_base_dir = os.path.join(base_dir, CSV_DIR_RELATIVE_PATH)

    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¿½åŠ 
    logger.info(f"ã‚¢ãƒ—ãƒªãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹: {current_app.root_path}")
    logger.info(f"ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {base_dir}")
    logger.info(f"CSVãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {csv_base_dir}")
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèª
    if os.path.exists(csv_base_dir):
        logger.info(f"CSVãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã™: {csv_base_dir}")
        files_in_dir = os.listdir(csv_base_dir)
        logger.info(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«: {files_in_dir}")
    else:
        logger.warning(f"CSVãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_base_dir}")

    all_knowledge_data = []

    for file_name, group in FILE_GROUP_MAP.items():
        csv_file_path = os.path.join(csv_base_dir, file_name)

        if not os.path.exists(csv_file_path):
            logger.warning(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_file_path}")
            continue

        logger.info(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­: {csv_file_path}")
        
        try:
            # æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®csvãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ç”¨
            with open(csv_file_path, 'r', encoding='utf-8-sig', newline='') as file:
                csv_reader = csv.reader(file)
                row_count = 0
                for row in csv_reader:
                    if len(row) >= 2 and row[0] and row[1]:  # ç©ºè¡Œã‚„ä¸å®Œå…¨ãªè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                        knowledge_item = {
                            "id": len(all_knowledge_data) + 1,
                            "name": row[0].strip(),
                            "description": row[1].strip(),
                            "category": group
                        }
                        all_knowledge_data.append(knowledge_item)
                        row_count += 1
                        
                logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ« {file_name} ã‹ã‚‰ {row_count} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                        
        except UnicodeDecodeError:
            # UTF-8ã§èª­ã‚ãªã„å ´åˆã¯Shift_JISã§è©¦è¡Œ
            try:
                with open(csv_file_path, 'r', encoding='shift_jis', newline='') as file:
                    csv_reader = csv.reader(file)
                    row_count = 0
                    for row in csv_reader:
                        if len(row) >= 2 and row[0] and row[1]:
                            knowledge_item = {
                                "id": len(all_knowledge_data) + 1,
                                "name": row[0].strip(),
                                "description": row[1].strip(),
                                "category": group
                            }
                            all_knowledge_data.append(knowledge_item)
                            row_count += 1
                    logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ« {file_name} ã‹ã‚‰ {row_count} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ (Shift_JIS)")
            except Exception as e:
                logger.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {csv_file_path}: {e}")
                continue
        except Exception as e:
            logger.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {csv_file_path}: {e}")
            continue

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ç”Ÿæˆ
    filter_groups = list(FILE_GROUP_MAP.values())
    
    logger.info(f"è±†çŸ¥è­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(all_knowledge_data)}ä»¶")
    logger.info(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚°ãƒ«ãƒ¼ãƒ—: {filter_groups}")
    
    return all_knowledge_data, filter_groups  # 2ã¤ã®å€¤ã‚’è¿”ã™

def get_all_knowledge_data():
    """è±†çŸ¥è­˜ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    knowledge_data, _ = load_knowledge_data()  # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚°ãƒ«ãƒ¼ãƒ—ã¯ç„¡è¦–
    return knowledge_data


# 2. ãƒ«ãƒ¼ãƒˆã‚’å®šç¾© (å¤‰æ›´ãªã—)
@bp.route('/')
def knowledge():
    # filter_groups ãŒ 'categories' ã¨ã—ã¦ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«æ¸¡ã•ã‚Œã‚‹
    knowledge_data, filter_groups = load_knowledge_data()
    

    # ---ã€‡å¤‰æ›´ç‚¹---
    # ãƒ­ã‚°ã‚¤ãƒ³ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¿å­˜æ¸ˆã¿ã‚¢ãƒ¬ãƒ³ã‚¸ãƒ¬ã‚·ãƒ”ã‚’å–å¾—
    arrange_list = []
    if 'user_id' in session:
        db = next(get_db())
        try:
            # ãƒ¬ã‚·ãƒ”ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ï¼ˆç©ºã§ãªã„ã‚‚ã®ï¼‰ã‚’å–å¾—
            records = db.query(arrange_suggest).filter(
                arrange_suggest.user_id == session['user_id'],
                arrange_suggest.arrange_recipe != None,
                arrange_suggest.arrange_recipe != ""
            ).all()
            
            for r in records:
                arrange_list.append({
                    'item_name': r.item_name,
                    'recipe': r.arrange_recipe
                })
        except Exception as e:
            print(f"ãƒ¬ã‚·ãƒ”å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            db.close()
    # ---ã“ã“ã¾ã§---

    return render_template('knowledge.html', 
                            knowledge_list=knowledge_data, 
                            categories=filter_groups, # ã“ã“ã« ['æ–™ç†', 'æƒé™¤', 'ãã®ä»–'] ã®ãƒªã‚¹ãƒˆãŒå…¥ã‚‹
                            arrange_list=arrange_list, # å¤‰æ›´: ãƒ¬ã‚·ãƒ”ãƒªã‚¹ãƒˆã‚’ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«æ¸¡ã™
                            active_page='knowledge')
